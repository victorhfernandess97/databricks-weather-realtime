{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d668abe7-5a9b-4526-bdc5-7ac78c7297b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6890ac-3bed-43b9-8393-de9816b62bef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.get(\"kvweather\", \"tomorrowio-api-key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c25b294-768c-41bc-af32-93a8cc745734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. pegar segredo\n",
    "api_key = dbutils.secrets.get(\"kvweather\", \"tomorrowio-api-key\")\n",
    "\n",
    "# 2. endpoint realtime\n",
    "url = f\"https://api.tomorrow.io/v4/weather/realtime?location=Brasilia&apikey={api_key}\"\n",
    "\n",
    "# 3. chamada\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# 4. caminho bronze/input\n",
    "output_path = \"abfss://datalake@realtimest.dfs.core.windows.net/bronze/input\"\n",
    "\n",
    "# 5. gerar nome do arquivo\n",
    "timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"{output_path}/weather_{timestamp}.json\"\n",
    "\n",
    "# 6. salvar arquivo em texto\n",
    "spark.createDataFrame([{\"payload\": json.dumps(data)}]) \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .text(filename)\n",
    "\n",
    "print(f\"Arquivo gerado: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00.baixa_arquivo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
